Sentiment Analysis with DistilBERT (IMDB Dataset)
This repository contains a project on Sentiment Analysis using the DistilBERT (uncased) model, a lightweight and efficient version of BERT. The project leverages the IMDB dataset, which contains 50,000 movie reviews categorized as positive or negative, to train and evaluate the model for classifying sentiment.

Key Features
Model Used: DistilBERT (uncased), a distilled version of BERT that is faster and more resource-efficient while maintaining high performance.
Dataset: IMDB movie reviews dataset with balanced positive and negative labels.
Preprocessing: Tokenization and input preparation using Hugging Face's Transformers library.
Training and Evaluation: Fine-tuned the DistilBERT model on the IMDB dataset and achieved high accuracy in sentiment classification.
Frameworks: PyTorch and Hugging Face Transformers library for model handling and training.
